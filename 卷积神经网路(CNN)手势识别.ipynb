{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from superai.nn.layer.fc import FullyConnected\n",
    "from superai.nn.layer.conv import Conv\n",
    "from superai.nn.layer.pool import PoolingLayer\n",
    "from superai.nn.layer.activator import Activator\n",
    "from superai.nn.layer.flatten import Flatten\n",
    "from superai.nn.model.nnet import Sequence\n",
    "from superai.nn.optimizer.adam import Adam\n",
    "from common import *\n",
    "\n",
    "# load hand sign data\n",
    "X_train, Y_train, X_test, Y_test = load_signs_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration1  cost:8.056411654719588, accuracy:0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoeliu/Other/AI/AI框架实现/superai/common/loss.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "  log_likelihood = -np.log(p[idx, range(m)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration2  cost:inf, accuracy:0.17000000000000004\n",
      "iteration3  cost:161.24185970491905, accuracy:0.18000000000000005\n",
      "iteration4  cost:inf, accuracy:0.18000000000000005\n",
      "iteration5  cost:28.023295982279137, accuracy:0.13\n",
      "iteration6  cost:19.776158797258418, accuracy:0.18000000000000005\n",
      "iteration7  cost:3.9243454466841206, accuracy:0.17000000000000004\n",
      "iteration8  cost:1.8164400990113156, accuracy:0.18000000000000005\n",
      "iteration9  cost:1.7981940203401428, accuracy:0.18000000000000005\n",
      "iteration10  cost:1.7927088646750904, accuracy:0.18000000000000005\n",
      "iteration11  cost:1.7897282211908896, accuracy:0.18999999999999995\n",
      "iteration12  cost:1.7880082263759345, accuracy:0.19999999999999996\n",
      "iteration13  cost:1.7869749361098883, accuracy:0.19999999999999996\n",
      "iteration14  cost:1.7863295215917898, accuracy:0.19999999999999996\n",
      "iteration15  cost:1.7859041963556288, accuracy:0.19999999999999996\n",
      "iteration16  cost:1.7856071968411067, accuracy:0.19999999999999996\n",
      "iteration17  cost:1.7853870459930155, accuracy:0.19999999999999996\n",
      "iteration18  cost:1.7852180616725377, accuracy:0.19999999999999996\n",
      "iteration19  cost:1.7850809322345327, accuracy:0.19999999999999996\n",
      "iteration20  cost:1.7849604474223824, accuracy:0.19999999999999996\n",
      "iteration21  cost:1.7848501218912056, accuracy:0.19999999999999996\n",
      "iteration22  cost:1.7847460315966202, accuracy:0.19999999999999996\n",
      "iteration23  cost:1.784645790776942, accuracy:0.20999999999999996\n",
      "iteration24  cost:1.7845479420405734, accuracy:0.20999999999999996\n",
      "iteration25  cost:1.784451590494194, accuracy:0.20999999999999996\n",
      "iteration26  cost:1.7843560364111801, accuracy:0.20999999999999996\n",
      "iteration27  cost:1.7842580331650058, accuracy:0.21999999999999997\n",
      "iteration28  cost:1.7841603340764234, accuracy:0.24\n",
      "iteration29  cost:1.7840628139112624, accuracy:0.24\n",
      "iteration30  cost:1.783965390169431, accuracy:0.24\n",
      "iteration31  cost:1.7838680067528967, accuracy:0.25\n",
      "iteration32  cost:1.7837707006926076, accuracy:0.26\n",
      "iteration33  cost:1.783673842357624, accuracy:0.24\n",
      "iteration34  cost:1.7835769215076067, accuracy:0.25\n",
      "iteration35  cost:1.7834799196847269, accuracy:0.25\n",
      "iteration36  cost:1.7833828209051814, accuracy:0.25\n",
      "iteration37  cost:1.7832856107636958, accuracy:0.25\n",
      "iteration38  cost:1.7831882758739739, accuracy:0.25\n",
      "iteration39  cost:1.7830908035180983, accuracy:0.25\n",
      "iteration40  cost:1.7829931814262088, accuracy:0.25\n",
      "iteration41  cost:1.782895397637554, accuracy:0.25\n",
      "iteration42  cost:1.782797440412473, accuracy:0.25\n",
      "iteration43  cost:1.7826992981763123, accuracy:0.25\n",
      "iteration44  cost:1.7826009143562305, accuracy:0.25\n",
      "iteration45  cost:1.7825019666432893, accuracy:0.25\n",
      "iteration46  cost:1.7824027983757444, accuracy:0.25\n",
      "iteration47  cost:1.782303414970223, accuracy:0.25\n",
      "iteration48  cost:1.7822038196947994, accuracy:0.25\n",
      "iteration49  cost:1.78210396943459, accuracy:0.25\n",
      "iteration50  cost:1.7820038240310736, accuracy:0.24\n",
      "iteration51  cost:1.781903404178035, accuracy:0.24\n",
      "iteration52  cost:1.7818029338233419, accuracy:0.24\n",
      "iteration53  cost:1.781704254960002, accuracy:0.24\n",
      "iteration54  cost:1.7816052309426071, accuracy:0.24\n",
      "iteration55  cost:1.7815059207875068, accuracy:0.24\n",
      "iteration56  cost:1.7814088160375996, accuracy:0.24\n",
      "iteration57  cost:1.781311296583032, accuracy:0.24\n",
      "iteration58  cost:1.7812133446308756, accuracy:0.24\n",
      "iteration59  cost:1.7811149453187776, accuracy:0.24\n",
      "iteration60  cost:1.781016085796938, accuracy:0.24\n",
      "iteration61  cost:1.780916754598678, accuracy:0.24\n",
      "iteration62  cost:1.780816941207737, accuracy:0.24\n",
      "iteration63  cost:1.7807166357600663, accuracy:0.24\n",
      "iteration64  cost:1.780615828837824, accuracy:0.24\n",
      "iteration65  cost:1.7805145113267538, accuracy:0.24\n",
      "iteration66  cost:1.7804126743172524, accuracy:0.24\n",
      "iteration67  cost:1.7803103090356034, accuracy:0.24\n",
      "iteration68  cost:1.780207406796101, accuracy:0.24\n",
      "iteration69  cost:1.7801039589911953, accuracy:0.24\n",
      "iteration70  cost:1.7799999570224019, accuracy:0.24\n",
      "iteration71  cost:1.7798953830812265, accuracy:0.24\n",
      "iteration72  cost:1.7797902139456292, accuracy:0.24\n",
      "iteration73  cost:1.779684464506686, accuracy:0.24\n",
      "iteration74  cost:1.7795783459150933, accuracy:0.24\n",
      "iteration75  cost:1.7794707460205894, accuracy:0.24\n",
      "iteration76  cost:1.7793606720904995, accuracy:0.24\n",
      "iteration77  cost:1.7792499243671214, accuracy:0.24\n",
      "iteration78  cost:1.7791384921513733, accuracy:0.24\n",
      "iteration79  cost:1.7790263653762102, accuracy:0.25\n",
      "iteration80  cost:1.778913534397076, accuracy:0.25\n",
      "iteration81  cost:1.7788000404532134, accuracy:0.25\n",
      "iteration82  cost:1.7786858665987193, accuracy:0.25\n",
      "iteration83  cost:1.778570936794574, accuracy:0.25\n",
      "iteration84  cost:1.7784552685208328, accuracy:0.25\n",
      "iteration85  cost:1.778338852544529, accuracy:0.25\n",
      "iteration86  cost:1.7782217397023083, accuracy:0.25\n",
      "iteration87  cost:1.7781038740471737, accuracy:0.25\n",
      "iteration88  cost:1.7779851840413081, accuracy:0.25\n",
      "iteration89  cost:1.7778657826249396, accuracy:0.25\n",
      "iteration90  cost:1.7777457409626047, accuracy:0.25\n",
      "iteration91  cost:1.7776247880881335, accuracy:0.25\n",
      "iteration92  cost:1.7775031154144194, accuracy:0.25\n",
      "iteration93  cost:1.7773806450995133, accuracy:0.25\n",
      "iteration94  cost:1.7772573001237584, accuracy:0.25\n",
      "iteration95  cost:1.777133182273331, accuracy:0.25\n",
      "iteration96  cost:1.7770077653529028, accuracy:0.25\n",
      "iteration97  cost:1.7768816696911534, accuracy:0.25\n",
      "iteration98  cost:1.7767546323247174, accuracy:0.25\n",
      "iteration99  cost:1.77662682766284, accuracy:0.25\n",
      "iteration100  cost:1.7764981778448803, accuracy:0.25\n",
      "iteration101  cost:1.7763685930906201, accuracy:0.25\n",
      "iteration102  cost:1.7762382771731167, accuracy:0.24\n",
      "iteration103  cost:1.7761066985280343, accuracy:0.24\n",
      "iteration104  cost:1.7759690138609572, accuracy:0.24\n",
      "iteration105  cost:1.7758304716452222, accuracy:0.24\n",
      "iteration106  cost:1.7756911178879267, accuracy:0.24\n",
      "iteration107  cost:1.7755507844096599, accuracy:0.24\n",
      "iteration108  cost:1.7754095583720564, accuracy:0.24\n",
      "iteration109  cost:1.7752674298207762, accuracy:0.25\n",
      "iteration110  cost:1.7751251663549052, accuracy:0.25\n",
      "iteration111  cost:1.7749887902439718, accuracy:0.25\n",
      "iteration112  cost:1.7748515353103718, accuracy:0.25\n",
      "iteration113  cost:1.7747133267723294, accuracy:0.25\n",
      "iteration114  cost:1.7745742280199195, accuracy:0.25\n",
      "iteration115  cost:1.7744342330407006, accuracy:0.25\n",
      "iteration116  cost:1.7742933651333472, accuracy:0.25\n",
      "iteration117  cost:1.774151625081179, accuracy:0.25\n",
      "iteration118  cost:1.7740090125733758, accuracy:0.25\n",
      "iteration119  cost:1.7738654665705653, accuracy:0.25\n",
      "iteration120  cost:1.7737209782434362, accuracy:0.25\n",
      "iteration121  cost:1.7735755387686267, accuracy:0.25\n",
      "iteration122  cost:1.7734251047427343, accuracy:0.25\n",
      "iteration123  cost:1.7732544527188452, accuracy:0.26\n",
      "iteration124  cost:1.7730804471596933, accuracy:0.26\n",
      "iteration125  cost:1.772903180377287, accuracy:0.26\n",
      "iteration126  cost:1.7727320086788296, accuracy:0.26\n",
      "iteration127  cost:1.7725553393200826, accuracy:0.27\n",
      "iteration128  cost:1.7723737482603252, accuracy:0.27\n",
      "iteration129  cost:1.7721966179385076, accuracy:0.26\n",
      "iteration130  cost:1.7720166532006598, accuracy:0.26\n",
      "iteration131  cost:1.7718261635371433, accuracy:0.26\n",
      "iteration132  cost:1.7716714962404203, accuracy:0.26\n",
      "iteration133  cost:1.7715173164937017, accuracy:0.25\n",
      "iteration134  cost:1.7713635962893917, accuracy:0.25\n",
      "iteration135  cost:1.7712089049175719, accuracy:0.26\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "pad = compute_samemode_pad(64, 64, (4, 4), (1, 1))\n",
    "cnn_layer1 = Conv((3, 4, 4), 8, pad, (1, 1))\n",
    "cnn_layer1.layer = 1\n",
    "relu1 = Activator(\"relu\")\n",
    "\n",
    "pad = compute_samemode_pad(64, 64, (8, 8), (8, 8))\n",
    "pool_layer1 = PoolingLayer((8, 8), pad, 'max', (8, 8))\n",
    "\n",
    "pad = compute_samemode_pad(57, 57, (2, 2), (1, 1))\n",
    "cnn_layer2 = Conv((8, 2, 2), 16, pad, (1, 1))\n",
    "cnn_layer2.layer = 2\n",
    "relu2 = Activator(\"relu\")\n",
    "\n",
    "pad = compute_samemode_pad(8, 8, (4, 4), (4, 4))\n",
    "pool_layer2 = PoolingLayer((4, 4), pad, 'max', (4, 4))\n",
    "\n",
    "flatten = Flatten()\n",
    "dense = FullyConnected(64, 6)\n",
    "\n",
    "model = Sequence([cnn_layer1, relu1, pool_layer1, cnn_layer2, relu2, pool_layer2, flatten, dense], learning_rate=0.01, iteration_count=100, use_mini_batch=True, mini_batch_size=64)\n",
    "'''\n",
    "cnn_layer1 = Conv((3, 5, 5), 16, (2, 2, 2, 2), (1, 1))\n",
    "cnn_layer1.layer = 1\n",
    "relu1 = Activator(\"relu\")\n",
    "pool_layer1 = PoolingLayer((2, 2), (0,0,0,0), 'max', (2, 2))\n",
    "cnn_layer2 = Conv((16, 5, 5), 20, (2, 2, 2, 2), (1, 1))\n",
    "cnn_layer2.layer = 2\n",
    "relu2 = Activator(\"relu\")\n",
    "pool_layer2 = PoolingLayer((2, 2), (0,0,0,0), 'max', (2, 2))\n",
    "\n",
    "flatten = Flatten()\n",
    "dense = FullyConnected(5120, 6)\n",
    "\n",
    "model = Sequence([cnn_layer1, relu1, pool_layer1, cnn_layer2, relu2, pool_layer2, flatten, dense], learning_rate=0.01, iteration_count=300)\n",
    "model.fit(X_train[:, :, :,0:100], Y_train[:, 0:100])\n",
    "# adamOpt = Adam()\n",
    "# adamOpt.run(model, X_train[:, :, :, 0:1000], Y_train[: , 0:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
